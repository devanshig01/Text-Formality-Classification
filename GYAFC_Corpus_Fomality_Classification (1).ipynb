{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATW73OQSQrrW"
      },
      "source": [
        "# NLP Final Project- Formality Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqH5ZZKQQxA7"
      },
      "source": [
        "## 1. Load the Dataset\n",
        "\n",
        "We will load the dataset and visualize the data outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnC6IoyPK_J3",
        "outputId": "f8139a20-c026-4067-99de-cefa5ad38a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "model_outputs  test  train  tune\n"
          ]
        }
      ],
      "source": [
        "# Importing dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Unzip dataset\n",
        "#!unzip /content/drive/MyDrive/NLP\\ Project/GYAFC_Corpus.zip -d /content/drive/MyDrive/NLP\\ Project/\n",
        "\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "!ls \"/content/drive/MyDrive/NLP Project/GYAFC_Corpus/Entertainment_Music\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC8ILDDOltfb",
        "outputId": "097327c4-fb34-4a85-ba1e-b4854bab5dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaP5v2o-2bYY",
        "outputId": "751b6f49-d3b0-4f0d-f937-2c06b1adbb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 30 20:04:50 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8kw3SItMbNe"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/drive/MyDrive/NLP Project/GYAFC_Corpus/Entertainment_Music'\n",
        "import os\n",
        "# Function to read the sentences from a file\n",
        "def load_sentences(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        sentences = file.readlines()\n",
        "    return [s.strip() for s in sentences]  # Strip to remove any extra whitespace\n",
        "\n",
        "# Paths to the files\n",
        "formal_file_path = os.path.join(base_path, 'train', 'formal')\n",
        "informal_file_path = os.path.join(base_path, 'train', 'informal')\n",
        "\n",
        "test_formal_file_path = os.path.join(base_path, 'test', 'formal')\n",
        "test_informal_file_path = os.path.join(base_path, 'test', 'informal')\n",
        "\n",
        "# Load the sentences\n",
        "formal_sentences = load_sentences(formal_file_path)\n",
        "informal_sentences = load_sentences(informal_file_path)\n",
        "\n",
        "test_formal_sentences = load_sentences(test_formal_file_path)\n",
        "test_informal_sentences = load_sentences(test_informal_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMoSESc2PLuL",
        "outputId": "8d4e8630-96b5-4ccf-f18d-a5f90c609ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 2 Informal Sentences: ['the movie The In-Laws not exactly a holiday movie but funny and good!', 'that page did not give me viroses(i think)']\n",
            "First 2 Formal Sentences: [\"The In-Laws movie isn't a holiday movie, but it's okay.\", \"I don't think that page gave me viruses.\"]\n",
            "First 2 Test Informal Sentences: ['Is Any Baby Really A Freak.', 'aspen colorado has he best music festivals, you sit all over the moutians its  on and just hang out']\n",
            "First 2 Test Formal Sentences: ['I like Rhythm and Blue music.', \"There's nothing he needs to change.\"]\n",
            "Number of Formal Sentences: 52595\n",
            "Number of Informal Sentences: 52595\n",
            "Number of Test Formal Sentences: 1082\n",
            "Number of Test Informal Sentences: 1416\n"
          ]
        }
      ],
      "source": [
        "# Check the first 2 loaded sentences\n",
        "print(\"First 2 Informal Sentences:\", informal_sentences[:2])\n",
        "print(\"First 2 Formal Sentences:\", formal_sentences[:2])\n",
        "\n",
        "print(\"First 2 Test Informal Sentences:\", test_informal_sentences[:2])\n",
        "print(\"First 2 Test Formal Sentences:\", test_formal_sentences[:2])\n",
        "\n",
        "# Count the number of sentences\n",
        "num_formal_sentences = len(formal_sentences)\n",
        "num_informal_sentences = len(informal_sentences)\n",
        "\n",
        "print(\"Number of Formal Sentences:\", num_formal_sentences)\n",
        "print(\"Number of Informal Sentences:\", num_informal_sentences)\n",
        "\n",
        "print(\"Number of Test Formal Sentences:\", len(test_formal_sentences))\n",
        "print(\"Number of Test Informal Sentences:\", len(test_informal_sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTpu8y_wRMIa"
      },
      "source": [
        "## 2. Preprocessing Data\n",
        "\n",
        "We will use **Character-based preprocessing.** This method involves converting all text to a uniform case, tokenizing at the character level, and padding sequences to a fixed length.\n",
        "\n",
        "It has higher accuracy in the paper (https://arxiv.org/pdf/2204.08975.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYCEN6iQRV56",
        "outputId": "63402e9e-e5f6-466b-df2f-1909a01e3a64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded Sequences:\n",
            " [[ 3  9  2 ...  0  0  0]\n",
            " [ 6  1 12 ...  0  0  0]]\n",
            "Labels: [1, 1]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Combine the datasets\n",
        "all_sentences = formal_sentences + informal_sentences\n",
        "\n",
        "test_all_sentences = test_formal_sentences + test_informal_sentences\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(all_sentences)\n",
        "\n",
        "tokenizer.fit_on_texts(test_all_sentences)\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(all_sentences)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_all_sentences)\n",
        "\n",
        "# Padding sequences\n",
        "max_length = max([len(seq) for seq in sequences])  # Or you can define a max length\n",
        "X_padded = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "test_X_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Prepare labels\n",
        "y = [1] * len(formal_sentences) + [0] * len(informal_sentences)  # 1 for formal, 0 for informal\n",
        "test_y = [1] * len(test_formal_sentences) + [0] * len(test_informal_sentences)  # 1 for formal, 0 for informal\n",
        "\n",
        "# Print the first 2 padded sequences and labels\n",
        "\n",
        "print(\"Padded Sequences:\\n\", X_padded[:2])  # Show first two padded sequences\n",
        "print(\"Labels:\", y[:2])  # Show first two labels\n",
        "\n",
        "# Model Input\n",
        "X = X_padded\n",
        "test_X = test_X_padded\n",
        "\n",
        "# Model Output\n",
        "y = y\n",
        "test_y = test_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aQOMXfMSISb"
      },
      "source": [
        "## 3. Train our Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJbjvW9TSM4W"
      },
      "source": [
        "### 3.1 BiLSTM Model - Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWzuaniOSCV5",
        "outputId": "42f6c2c9-2c37-4967-e9fc-ddef2d836f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> (105190, 3999)\n",
            "<class 'numpy.ndarray'> (105190,)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 3999, 50)          6350      \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 100)               40400     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46851 (183.01 KB)\n",
            "Trainable params: 46851 (183.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1315/1315 [==============================] - 290s 218ms/step - loss: 0.5329 - accuracy: 0.7354 - val_loss: 0.6213 - val_accuracy: 0.6311\n",
            "Epoch 2/5\n",
            "1315/1315 [==============================] - 285s 217ms/step - loss: 0.4218 - accuracy: 0.8169 - val_loss: 0.4667 - val_accuracy: 0.7486\n",
            "Epoch 3/5\n",
            "1315/1315 [==============================] - 286s 218ms/step - loss: 0.3961 - accuracy: 0.8264 - val_loss: 0.5753 - val_accuracy: 0.6858\n",
            "Epoch 4/5\n",
            "1315/1315 [==============================] - 286s 217ms/step - loss: 0.3762 - accuracy: 0.8366 - val_loss: 0.5352 - val_accuracy: 0.7149\n",
            "Epoch 5/5\n",
            "1315/1315 [==============================] - 285s 217ms/step - loss: 0.3619 - accuracy: 0.8423 - val_loss: 0.5505 - val_accuracy: 0.7156\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bd4dd6eb940>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_padded is already defined as shown in previous steps\n",
        "# Convert X_padded and y to NumPy arrays if they aren't already\n",
        "X = np.array(X_padded)\n",
        "y = np.array(y)\n",
        "\n",
        "# Verify that X and y are now NumPy arrays\n",
        "print(type(X), X.shape)\n",
        "print(type(y), y.shape)\n",
        "\n",
        "\n",
        "# Define the BiLSTM model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=max_length),\n",
        "    Bidirectional(LSTM(units=50)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=5, batch_size=64, validation_split=0.2)  # Adjust epochs, batch_size, and validation_split as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "predictions = model.predict(test_X)\n",
        "binary_predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "precision = precision_score(test_y, binary_predictions)\n",
        "recall = recall_score(test_y, binary_predictions)\n",
        "f1 = f1_score(test_y, binary_predictions)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x60SNVBvqquY",
        "outputId": "6fd1e500-901d-4508-a1d3-b14cca6ba122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 7s 77ms/step\n",
            "Precision: 0.6819085487077535\n",
            "Recall: 0.9510166358595195\n",
            "F1 Score: 0.7942879197221151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvQanKrhs1KN"
      },
      "source": [
        "### 3.2 DeBerta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u76CLAqVtDNO",
        "outputId": "e15a1ed6-92e3-4899-d56d-ea26e44a8be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import sentencepiece\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import DebertaV2Model, DebertaV2Config, DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
        "MODEL_NAME = 'microsoft/deberta-v3-base'\n",
        "model = DebertaV2ForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels=2)  # Adjust num_labels accordingly\n",
        "config = DebertaV2Config.from_pretrained(MODEL_NAME)\n",
        "tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
        "from transformers import EarlyStoppingCallback\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "# Prepare dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=64)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import Trainer, TrainingArguments\n",
        "#tokenize dataset as per DeBerta\n",
        "#split the data 80 and 20 first\n",
        "\n",
        "train_dataset = TextDataset(all_sentences, y)\n",
        "eval_dataset = TextDataset(test_all_sentences, test_y)\n",
        "#! pip install --force-reinstall accelerate transformers[torch]\n",
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "GcxWYSPTxvsO",
        "outputId": "3a7f7e1f-7276-45d8-c1fe-40963c06e920"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39447' max='39447' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39447/39447 2:05:19, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.208600</td>\n",
              "      <td>0.249078</td>\n",
              "      <td>0.933147</td>\n",
              "      <td>0.874080</td>\n",
              "      <td>0.987985</td>\n",
              "      <td>0.927549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.168200</td>\n",
              "      <td>0.193932</td>\n",
              "      <td>0.949560</td>\n",
              "      <td>0.903716</td>\n",
              "      <td>0.988909</td>\n",
              "      <td>0.944395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.119500</td>\n",
              "      <td>0.263381</td>\n",
              "      <td>0.940753</td>\n",
              "      <td>0.886589</td>\n",
              "      <td>0.989834</td>\n",
              "      <td>0.935371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=39447, training_loss=0.1748655514895159, metrics={'train_runtime': 7520.6472, 'train_samples_per_second': 41.96, 'train_steps_per_second': 5.245, 'total_flos': 1.037893059825408e+16, 'train_loss': 0.1748655514895159, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#Training\n",
        "# !pip install transformers[torch]\n",
        "#!pip install accelerate -U\n",
        "\n",
        "\n",
        "#! pip install --force-reinstall accelerate transformers[torch]\n",
        "\n",
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # where to save the model\n",
        "    evaluation_strategy=\"epoch\",     # evaluate each epoch\n",
        "    save_strategy=\"epoch\",           # save model each epoch\n",
        "    learning_rate=2e-5,              # learning rate\n",
        "    per_device_train_batch_size=8,   # batch size for training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    num_train_epochs=3,              # number of epochs\n",
        "    weight_decay=0.01,               # weight decay\n",
        "    logging_dir='./logs',            # where to store logs\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,  # your encoded and prepared training dataset\n",
        "    eval_dataset=eval_dataset,    # your encoded and prepared validation dataset\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u0sJFb2qBe_8",
        "outputId": "025c7623-2984-4322-ebc8-b3b4da4aa371"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "model = DebertaV2ForSequenceClassification.from_pretrained('./results/checkpoint-39447')\n",
        "test_trainer = Trainer(model)\n",
        "\n",
        "raw_pred, _, _ = test_trainer.predict(eval_dataset)\n",
        "y_pred = np.argmax(raw_pred, axis=1)\n",
        "print(y_pred)\n",
        "#tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "#model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    'Sentence': test_all_sentences,  # Adjust field name as necessary\n",
        "    'Predicted Label': y_pred,\n",
        "    'Actual Label': test_y  # Adjust field name as necessary\n",
        "}\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "7xVGZlJTLgq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
        "print(df_shuffled.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDWYGf65MLBj",
        "outputId": "8e478a0e-81a8-424e-be58-2437e48c1931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Sentence  Predicted Label  \\\n",
            "0                      They are the best metal band.                1   \n",
            "1  rapp because u can ryhmn and spit crapbut in r...                0   \n",
            "2                   He didn't want to be a bigamist.                1   \n",
            "3             i want a him and will call him 'money'                0   \n",
            "4  Thus far, I have not heard that she returns he...                1   \n",
            "\n",
            "   Actual Label  \n",
            "0             1  \n",
            "1             0  \n",
            "2             0  \n",
            "3             0  \n",
            "4             1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0Lr0P_Dk8xN"
      },
      "source": [
        "### 3.3 Bert (un-cased)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buuFkEKq6rEh",
        "outputId": "7c7c9dc2-b87e-4751-dde2-acb88256b739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "\n",
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=64)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = TextDataset(all_sentences, y)\n",
        "eval_dataset = TextDataset(test_all_sentences, test_y)\n",
        "#! pip install --force-reinstall accelerate transformers[torch]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "cZKVVVgt63Da",
        "outputId": "4b952ba8-793b-4834-ccbe-6bc1d4b9b322"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39447' max='39447' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39447/39447 1:17:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.518100</td>\n",
              "      <td>0.397858</td>\n",
              "      <td>0.871497</td>\n",
              "      <td>0.801745</td>\n",
              "      <td>0.934381</td>\n",
              "      <td>0.862996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.572600</td>\n",
              "      <td>0.521684</td>\n",
              "      <td>0.784227</td>\n",
              "      <td>0.911988</td>\n",
              "      <td>0.555453</td>\n",
              "      <td>0.690408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.694700</td>\n",
              "      <td>0.691717</td>\n",
              "      <td>0.566853</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=39447, training_loss=0.5511827216715427, metrics={'train_runtime': 4638.3315, 'train_samples_per_second': 68.035, 'train_steps_per_second': 8.505, 'total_flos': 1.03787444674944e+16, 'train_loss': 0.5511827216715427, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "\n",
        "#! pip install --force-reinstall accelerate transformers[torch]\n",
        "\n",
        "# Define Trainer parameters\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "# Define Trainer\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",     # evaluate each epoch\n",
        "    save_strategy=\"epoch\",           # save model each epoch\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")\n",
        "\n",
        "# Train pre-trained model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"./results/checkpoint-13149\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
        "\n",
        "raw_pred, _, _ = test_trainer.predict(eval_dataset)\n",
        "y_pred = np.argmax(raw_pred, axis=1)\n",
        "print(y_pred)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8T8IM98mfFGe",
        "outputId": "50ea327e-a604-4ef6-a249-210241f58f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    'Sentence': test_all_sentences,  # Adjust field name as necessary\n",
        "    'Predicted Label': y_pred,\n",
        "    'Actual Label': test_y  # Adjust field name as necessary\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
        "print(df_shuffled.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOPdyrvZfSGu",
        "outputId": "ece512ef-fca7-4a28-a1bb-8f201a13a2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Sentence  Predicted Label  \\\n",
            "0  my favorite english song is kiss from a rose b...                1   \n",
            "1                  neither...not a big fan of either                0   \n",
            "2  I am not fond of any of them. Panget Rock Band...                1   \n",
            "3           Goo Goo Dolls and Relient K are awesome!                0   \n",
            "4              Cheesy I know...but I love this joke.                0   \n",
            "\n",
            "   Actual Label  \n",
            "0             0  \n",
            "1             0  \n",
            "2             1  \n",
            "3             0  \n",
            "4             0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJeWYPMbeNu8"
      },
      "source": [
        "### 3.3 Simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoojmqO5ax5h"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(all_sentences)\n",
        "\n",
        "# Build model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 256\n",
        "\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
        "cnn_model.add(Conv1D(64, 3, activation='relu'))\n",
        "cnn_model.add(GlobalMaxPooling1D())\n",
        "cnn_model.add(Dense(32, activation='relu'))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "cnn_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "cnn_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[\"accuracy\", Precision(), Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdOtD5bOeEAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a9e1d9-3b84-4dfb-b2a6-f563f3e70d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5260/5260 [==============================] - 86s 16ms/step - loss: 0.4211 - accuracy: 0.8189 - precision_1: 0.8171 - recall_1: 0.9151 - val_loss: 0.4872 - val_accuracy: 0.7065 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
            "Epoch 2/10\n",
            "5260/5260 [==============================] - 83s 16ms/step - loss: 0.3787 - accuracy: 0.8386 - precision_1: 0.8384 - recall_1: 0.9188 - val_loss: 0.4072 - val_accuracy: 0.7948 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
            "Epoch 3/10\n",
            "5260/5260 [==============================] - 83s 16ms/step - loss: 0.3606 - accuracy: 0.8446 - precision_1: 0.8445 - recall_1: 0.9209 - val_loss: 0.5463 - val_accuracy: 0.7244 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
            "Epoch 4/10\n",
            "5260/5260 [==============================] - 83s 16ms/step - loss: 0.3504 - accuracy: 0.8488 - precision_1: 0.8490 - recall_1: 0.9221 - val_loss: 0.5037 - val_accuracy: 0.6914 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
            "Epoch 5/10\n",
            "5260/5260 [==============================] - 83s 16ms/step - loss: 0.3440 - accuracy: 0.8518 - precision_1: 0.8509 - recall_1: 0.9250 - val_loss: 0.4069 - val_accuracy: 0.7744 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
            "Epoch 6/10\n",
            "5260/5260 [==============================] - 83s 16ms/step - loss: 0.3403 - accuracy: 0.8537 - precision_1: 0.8525 - recall_1: 0.9262 - val_loss: 0.3907 - val_accuracy: 0.8035 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
            "Epoch 7/10\n",
            "5260/5260 [==============================] - 83s 16ms/step - loss: 0.3356 - accuracy: 0.8553 - precision_1: 0.8544 - recall_1: 0.9262 - val_loss: 0.4915 - val_accuracy: 0.7412 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
            "Epoch 8/10\n",
            "5260/5260 [==============================] - 83s 16ms/step - loss: 0.3319 - accuracy: 0.8575 - precision_1: 0.8565 - recall_1: 0.9273 - val_loss: 0.4293 - val_accuracy: 0.7827 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
            "Epoch 9/10\n",
            "5260/5260 [==============================] - 83s 16ms/step - loss: 0.3303 - accuracy: 0.8580 - precision_1: 0.8575 - recall_1: 0.9268 - val_loss: 0.4523 - val_accuracy: 0.7681 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
            "Epoch 10/10\n",
            "5260/5260 [==============================] - 83s 16ms/step - loss: 0.3262 - accuracy: 0.8599 - precision_1: 0.8593 - recall_1: 0.9278 - val_loss: 0.4698 - val_accuracy: 0.7557 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bd4dd8324d0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "\n",
        "# Train model\n",
        "X = np.array(X_padded)\n",
        "y = np.array(y)\n",
        "cnn_model.fit(X, y, batch_size=16, epochs=10, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "predictions = cnn_model.predict(test_X)\n",
        "binary_predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "precision = precision_score(test_y, binary_predictions)\n",
        "recall = recall_score(test_y, binary_predictions)\n",
        "f1 = f1_score(test_y, binary_predictions)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjMNvH81hnLM",
        "outputId": "a91e5c94-21bc-4adb-8344-b1ad3b645845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 8ms/step\n",
            "Precision: 0.7125256673511293\n",
            "Recall: 0.9621072088724584\n",
            "F1 Score: 0.818718049547778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cnn_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su3YHX8yhofJ",
        "outputId": "196bd54c-7825-4229-b681-5fc3279a9b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 3999, 256)         32512     \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 3997, 64)          49216     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Gl  (None, 64)                0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 83841 (327.50 KB)\n",
            "Trainable params: 83841 (327.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formality Score Calculations"
      ],
      "metadata": {
        "id": "QiHHDDzmh1uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Using the currently trained Bert Model, we can use it to predict formality score\n",
        "model = BertForSequenceClassification.from_pretrained('./results/checkpoint-13149')\n",
        "test_trainer = Trainer(model)\n",
        "\n",
        "raw_pred, _, _ = test_trainer.predict(eval_dataset)\n",
        "y_pred = np.argmax(raw_pred, axis=1)\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UczJGSwxh5Iy",
        "outputId": "56e1d915-40ac-4616-bcfb-3a84fa2626ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "test_50_sentences = df_shuffled[\"Sentence\"].tolist()[:50]\n",
        "test_50_labels = df_shuffled[\"Actual Label\"].tolist()[:50]"
      ],
      "metadata": {
        "id": "_a_IFsgilzvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-l8ivMGmIWx",
        "outputId": "b0664fb5-5e2e-4062-d133-736d908f1d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(test_50_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "y_pred = y_pred[:50]\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "    formality_scores = probabilities[:, 1].tolist()  # List of formality scores for each sentence\n"
      ],
      "metadata": {
        "id": "ZabC8cXxmQ4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text, score, pred, model_prediction in zip(test_50_sentences, formality_scores, test_50_labels, y_pred):\n",
        "    print(f\"Text: {text}\\nFormality Score: {score:.4f}\\nOriginal Prediction: {pred}\\nModel Prediction: {model_prediction}\\n\")\n",
        "\n",
        "#1 for formal, 0 is informal --> the closer the score is to 0, the more informal it is, otherwise the closer it is to 1, then that is how formal it is.ok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItD0ciK2mqX-",
        "outputId": "66289412-c229-4365-d35d-e9ae4b61638f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: my favorite english song is kiss from a rose by seal.\n",
            "Formality Score: 0.9577\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: neither...not a big fan of either\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: I am not fond of any of them. Panget Rock Band is the best.\n",
            "Formality Score: 0.9579\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Goo Goo Dolls and Relient K are awesome!\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Cheesy I know...but I love this joke.\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: You know the Beta team still wants to answer this.\n",
            "Formality Score: 0.9589\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: this does happen, like in batman, when he was recoving and that blond guy took over for a bit.\n",
            "Formality Score: 0.3605\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: A very close friend of mine is a Cap.\n",
            "Formality Score: 0.9578\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Where can I download music from after purchasing an MP120?\n",
            "Formality Score: 0.9595\n",
            "Original Prediction: 1\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: I attempted to enjoy his company but cannot.\n",
            "Formality Score: 0.9578\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Yes, it turned me into a human hose pipe.\n",
            "Formality Score: 0.9577\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: She's as trampy as the others!\n",
            "Formality Score: 0.0454\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: i just need some sick or ill rhymes about anything.\n",
            "Formality Score: 0.0454\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: it's the best metal band ever!!\n",
            "Formality Score: 0.0455\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: ok so is tht going to happen after 4000 years?\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: i don't know maybe you'll find it in her website\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: My favorite band is Dream Theater and my favorite song is called, 'Always Changing.'\n",
            "Formality Score: 0.9578\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: yes i actually bought one lmao\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: I am not familiar with any of them.\n",
            "Formality Score: 0.9578\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: it had to be the chickin.\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Please let me know when you find out.\n",
            "Formality Score: 0.9575\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: He picked Sarah but rumour has it that they have already broke up.\n",
            "Formality Score: 0.3826\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Dress her up as a Choirboy ...\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Just act like youve done it before and kick some a$$\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: well yes even i am bored here right now\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: The movie is Cheeh and Chongs 'Up In Smoke.'\n",
            "Formality Score: 0.9157\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: she saw a blonde on the other side.\n",
            "Formality Score: 0.8864\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: What were you and your dad doing?\n",
            "Formality Score: 0.3560\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Your mother is so unattractive, the police ticketed her for indecent exposure.\n",
            "Formality Score: 0.9579\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: People are unintelligent and wish to exploit him for his financial resources.\n",
            "Formality Score: 0.9577\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: I wish I could meet my fave bands.I love rap music.GO RELIENT K!\n",
            "Formality Score: 0.3673\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: and just tried to pull those dangly things!!\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: The movie is, 'Double Teamed'.\n",
            "Formality Score: 0.9592\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Your never satisfied with what you have.\n",
            "Formality Score: 0.9591\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: aspen colorado has he best music festivals, you sit all over the moutians its  on and just hang out\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: I am going to the HERSHEY factory tomorrow (I am so EXCITED!!!\n",
            "Formality Score: 0.9421\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: I am very surprised that your friends are not familiar with that show.\n",
            "Formality Score: 0.9579\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Jerry Springer b/c David letterman is a pu$$y LOL\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: i think they both stink if i had to pick one it would be italian job.\n",
            "Formality Score: 0.3708\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: but i dont watch him that much!\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: a chick from my church lauren h.\n",
            "Formality Score: 0.0454\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: He must of learned some skills after seeing all those fights.\n",
            "Formality Score: 0.9584\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: The Red Hot Chili Peppers are rated very highly.\n",
            "Formality Score: 0.9579\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: It's humorour, however, it's extremely inane.\n",
            "Formality Score: 0.9577\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: We also spell 'color' as 'colour' and its not c O lin Powell it's C o lin.\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Being a Def Leppard fan, I would get all of them from them.\n",
            "Formality Score: 0.9590\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: i think that celebrities are a horrible influence\n",
            "Formality Score: 0.9574\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: One of you would have to sing.\n",
            "Formality Score: 0.9581\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Although I find him marginally attractive, I find his wife exceptionally attractive.\n",
            "Formality Score: 0.9580\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: any movie with Jim Carrey in it!\n",
            "Formality Score: 0.0453\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}