# -*- coding: utf-8 -*-
"""GYAFC Corpus- Fomality Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NGlnDDAxG5PAtuvjxmdRyhSbZwtCMPsW

# NLP Final Project- Formality Classification

## 1. Load the Dataset

We will load the dataset and visualize the data outputs.
"""

# Importing dataset
from google.colab import drive
drive.mount('/content/drive')

# Unzip dataset
#!unzip /content/drive/MyDrive/NLP\ Project/GYAFC_Corpus.zip -d /content/drive/MyDrive/NLP\ Project/



# Load dataset
!ls "/content/drive/MyDrive/NLP Project/GYAFC_Corpus/Entertainment_Music"

from google.colab import drive
drive.mount('/content/drive')

import torch
import torch.nn as nn
import torch.nn.functional as F

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Select the Runtime > "Change runtime type" menu to enable a GPU accelerator, ')
  print('and then re-execute this cell.')
else:
  print(gpu_info)

base_path = '/content/drive/MyDrive/NLP Project/GYAFC_Corpus/Entertainment_Music'
import os
# Function to read the sentences from a file
def load_sentences(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        sentences = file.readlines()
    return [s.strip() for s in sentences]  # Strip to remove any extra whitespace

# Paths to the files
formal_file_path = os.path.join(base_path, 'train', 'formal')
informal_file_path = os.path.join(base_path, 'train', 'informal')

test_formal_file_path = os.path.join(base_path, 'test', 'formal')
test_informal_file_path = os.path.join(base_path, 'test', 'informal')

# Load the sentences
formal_sentences = load_sentences(formal_file_path)
informal_sentences = load_sentences(informal_file_path)

test_formal_sentences = load_sentences(test_formal_file_path)
test_informal_sentences = load_sentences(test_informal_file_path)

# Check the first 2 loaded sentences
print("First 2 Informal Sentences:", informal_sentences[:2])
print("First 2 Formal Sentences:", formal_sentences[:2])

print("First 2 Test Informal Sentences:", test_informal_sentences[:2])
print("First 2 Test Formal Sentences:", test_formal_sentences[:2])

# Count the number of sentences
num_formal_sentences = len(formal_sentences)
num_informal_sentences = len(informal_sentences)

print("Number of Formal Sentences:", num_formal_sentences)
print("Number of Informal Sentences:", num_informal_sentences)

print("Number of Test Formal Sentences:", len(test_formal_sentences))
print("Number of Test Informal Sentences:", len(test_informal_sentences))

"""## 2. Preprocessing Data

We will use **Character-based preprocessing.** This method involves converting all text to a uniform case, tokenizing at the character level, and padding sequences to a fixed length.

It has higher accuracy in the paper (https://arxiv.org/pdf/2204.08975.pdf)

"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Combine the datasets
all_sentences = formal_sentences + informal_sentences

test_all_sentences = test_formal_sentences + test_informal_sentences

# Initialize tokenizer
tokenizer = Tokenizer(char_level=True)
tokenizer.fit_on_texts(all_sentences)

tokenizer.fit_on_texts(test_all_sentences)
# Convert text to sequences
sequences = tokenizer.texts_to_sequences(all_sentences)
test_sequences = tokenizer.texts_to_sequences(test_all_sentences)

# Padding sequences
max_length = max([len(seq) for seq in sequences])  # Or you can define a max length
X_padded = pad_sequences(sequences, maxlen=max_length, padding='post')
test_X_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')

# Prepare labels
y = [1] * len(formal_sentences) + [0] * len(informal_sentences)  # 1 for formal, 0 for informal
test_y = [1] * len(test_formal_sentences) + [0] * len(test_informal_sentences)  # 1 for formal, 0 for informal

# Print the first 2 padded sequences and labels

print("Padded Sequences:\n", X_padded[:2])  # Show first two padded sequences
print("Labels:", y[:2])  # Show first two labels

# Model Input
X = X_padded
test_X = test_X_padded

# Model Output
y = y
test_y = test_y

"""## 3. Train our Models

### 3.1 BiLSTM Model - Baseline Model
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense

import numpy as np

# Assuming X_padded is already defined as shown in previous steps
# Convert X_padded and y to NumPy arrays if they aren't already
X = np.array(X_padded)
y = np.array(y)

# Verify that X and y are now NumPy arrays
print(type(X), X.shape)
print(type(y), y.shape)


# Define the BiLSTM model
model = Sequential([
    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=max_length),
    Bidirectional(LSTM(units=50)),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Model summary
model.summary()

# Train the model
model.fit(X, y, epochs=5, batch_size=64, validation_split=0.2)  # Adjust epochs, batch_size, and validation_split as needed

from sklearn.metrics import precision_score, recall_score, f1_score
predictions = model.predict(test_X)
binary_predictions = (predictions > 0.5).astype(int)

# Evaluate the model
precision = precision_score(test_y, binary_predictions)
recall = recall_score(test_y, binary_predictions)
f1 = f1_score(test_y, binary_predictions)

print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

"""### 3.2 DeBerta"""

import sentencepiece
import torch
from torch.utils.data import Dataset
from transformers import DebertaV2Model, DebertaV2Config, DebertaV2Tokenizer, DebertaV2ForSequenceClassification
MODEL_NAME = 'microsoft/deberta-v3-base'
model = DebertaV2ForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels=2)  # Adjust num_labels accordingly
config = DebertaV2Config.from_pretrained(MODEL_NAME)
tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)
from transformers import EarlyStoppingCallback
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score

# Prepare dataset
class TextDataset(Dataset):
    def __init__(self, texts, labels):
        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=64)
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)


from sklearn.model_selection import train_test_split
from transformers import Trainer, TrainingArguments
#tokenize dataset as per DeBerta
#split the data 80 and 20 first

train_dataset = TextDataset(all_sentences, y)
eval_dataset = TextDataset(test_all_sentences, test_y)
#! pip install --force-reinstall accelerate transformers[torch]
import torch, gc
gc.collect()
torch.cuda.empty_cache()

#Training
# !pip install transformers[torch]
#!pip install accelerate -U


#! pip install --force-reinstall accelerate transformers[torch]

import torch, gc
gc.collect()
torch.cuda.empty_cache()

def compute_metrics(p):
    pred, labels = p
    pred = np.argmax(pred, axis=1)

    accuracy = accuracy_score(y_true=labels, y_pred=pred)
    recall = recall_score(y_true=labels, y_pred=pred)
    precision = precision_score(y_true=labels, y_pred=pred)
    f1 = f1_score(y_true=labels, y_pred=pred)

    return {"accuracy": accuracy, "precision": precision, "recall": recall, "f1": f1}


training_args = TrainingArguments(
    output_dir='./results',          # where to save the model
    evaluation_strategy="epoch",     # evaluate each epoch
    save_strategy="epoch",           # save model each epoch
    learning_rate=2e-5,              # learning rate
    per_device_train_batch_size=8,   # batch size for training
    per_device_eval_batch_size=16,   # batch size for evaluation
    num_train_epochs=3,              # number of epochs
    weight_decay=0.01,               # weight decay
    logging_dir='./logs',            # where to store logs
    load_best_model_at_end=True,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,  # your encoded and prepared training dataset
    eval_dataset=eval_dataset,    # your encoded and prepared validation dataset
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],

)

# Train the model
trainer.train()

model = DebertaV2ForSequenceClassification.from_pretrained('./results/checkpoint-39447')
test_trainer = Trainer(model)

raw_pred, _, _ = test_trainer.predict(eval_dataset)
y_pred = np.argmax(raw_pred, axis=1)
print(y_pred)
#tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)

#model.eval()

import pandas as pd
data = {
    'Sentence': test_all_sentences,  # Adjust field name as necessary
    'Predicted Label': y_pred,
    'Actual Label': test_y  # Adjust field name as necessary
}
df = pd.DataFrame(data)

df_shuffled = df.sample(frac=1).reset_index(drop=True)
print(df_shuffled.head())

"""### 3.3 Bert (un-cased)"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score
import torch
from transformers import TrainingArguments, Trainer
from transformers import BertTokenizer, BertForSequenceClassification
from transformers import EarlyStoppingCallback


import torch, gc
gc.collect()
torch.cuda.empty_cache()

model_name = "bert-base-uncased"
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)



class TextDataset(Dataset):
    def __init__(self, texts, labels):
        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=64)
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = TextDataset(all_sentences, y)
eval_dataset = TextDataset(test_all_sentences, test_y)
#! pip install --force-reinstall accelerate transformers[torch]

#! pip install --force-reinstall accelerate transformers[torch]

# Define Trainer parameters
def compute_metrics(p):
    pred, labels = p
    pred = np.argmax(pred, axis=1)

    accuracy = accuracy_score(y_true=labels, y_pred=pred)
    recall = recall_score(y_true=labels, y_pred=pred)
    precision = precision_score(y_true=labels, y_pred=pred)
    f1 = f1_score(y_true=labels, y_pred=pred)

    return {"accuracy": accuracy, "precision": precision, "recall": recall, "f1": f1}

# Define Trainer
args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",     # evaluate each epoch
    save_strategy="epoch",           # save model each epoch
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    seed=0,
    load_best_model_at_end=True,
)
trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],
)

# Train pre-trained model
trainer.train()

model_path = "./results/checkpoint-13149"
model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)

raw_pred, _, _ = test_trainer.predict(eval_dataset)
y_pred = np.argmax(raw_pred, axis=1)
print(y_pred)

import pandas as pd
data = {
    'Sentence': test_all_sentences,  # Adjust field name as necessary
    'Predicted Label': y_pred,
    'Actual Label': test_y  # Adjust field name as necessary
}
df = pd.DataFrame(data)

df_shuffled = df.sample(frac=1).reset_index(drop=True)
print(df_shuffled.head())

"""### 3.3 Simple CNN"""

from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import Precision, Recall
from tensorflow.keras.preprocessing.text import Tokenizer

tokenizer = Tokenizer(char_level=True)
tokenizer.fit_on_texts(all_sentences)

# Build model
vocab_size = len(tokenizer.word_index) + 1
embedding_dim = 256

cnn_model = Sequential()
cnn_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))
cnn_model.add(Conv1D(64, 3, activation='relu'))
cnn_model.add(GlobalMaxPooling1D())
cnn_model.add(Dense(32, activation='relu'))
cnn_model.add(Dropout(0.5))
cnn_model.add(Dense(1, activation='sigmoid'))

optimizer = Adam(learning_rate=0.001)

cnn_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=["accuracy", Precision(), Recall()])

# Train model
X = np.array(X_padded)
y = np.array(y)
cnn_model.fit(X, y, batch_size=16, epochs=10, validation_split=0.2)

from sklearn.metrics import precision_score, recall_score, f1_score
predictions = cnn_model.predict(test_X)
binary_predictions = (predictions > 0.5).astype(int)

# Evaluate the model
precision = precision_score(test_y, binary_predictions)
recall = recall_score(test_y, binary_predictions)
f1 = f1_score(test_y, binary_predictions)

print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

print(cnn_model.summary())

"""### Formality Score Calculations"""

##Using the currently trained Bert Model, we can use it to predict formality score
model = BertForSequenceClassification.from_pretrained('./results/checkpoint-13149')
test_trainer = Trainer(model)

raw_pred, _, _ = test_trainer.predict(eval_dataset)
y_pred = np.argmax(raw_pred, axis=1)
print(y_pred)

model_name = "bert-base-uncased"
tokenizer = BertTokenizer.from_pretrained(model_name)

test_50_sentences = df_shuffled["Sentence"].tolist()[:50]
test_50_labels = df_shuffled["Actual Label"].tolist()[:50]

model.eval()

inputs = tokenizer(test_50_sentences, return_tensors="pt", padding=True, truncation=True, max_length=512)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
y_pred = y_pred[:50]
inputs = {k: v.to(device) for k, v in inputs.items()}

with torch.no_grad():
    outputs = model(**inputs)
    logits = outputs.logits
    probabilities = torch.nn.functional.softmax(logits, dim=1)
    formality_scores = probabilities[:, 1].tolist()  # List of formality scores for each sentence

for text, score, pred, model_prediction in zip(test_50_sentences, formality_scores, test_50_labels, y_pred):
    print(f"Text: {text}\nFormality Score: {score:.4f}\nOriginal Prediction: {pred}\nModel Prediction: {model_prediction}\n")

#1 for formal, 0 is informal --> the closer the score is to 0, the more informal it is, otherwise the closer it is to 1, then that is how formal it is.ok