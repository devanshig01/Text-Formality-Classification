{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATW73OQSQrrW"
      },
      "source": [
        "# Text Formality Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqH5ZZKQQxA7"
      },
      "source": [
        "## 1. Load the Dataset\n",
        "\n",
        "We will load the dataset and visualize the data outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnC6IoyPK_J3",
        "outputId": "278ef1f4-237d-4b54-ca45-7c30b2be70bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "model_outputs  test  train  tune\n"
          ]
        }
      ],
      "source": [
        "# Importing dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Unzip dataset\n",
        "#!unzip /content/drive/MyDrive/Text Formality Project/GYAFC_Corpus.zip -d /content/drive/MyDrive/Text Formality Project\n",
        "\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "!ls \"/content/drive/MyDrive/NLP Project/GYAFC_Corpus/Entertainment_Music\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC8ILDDOltfb",
        "outputId": "9c81bc42-768d-4baa-bf58-f8514cf40f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaP5v2o-2bYY",
        "outputId": "89919a35-1ca8-46ef-fd94-45fe1fdef939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 29 19:10:43 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8kw3SItMbNe"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/drive/MyDrive/Text Formality Project/GYAFC_Corpus/Entertainment_Music'\n",
        "import os\n",
        "# Function to read the sentences from a file\n",
        "def load_sentences(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        sentences = file.readlines()\n",
        "    return [s.strip() for s in sentences]  # Strip to remove any extra whitespace\n",
        "\n",
        "# Paths to the files\n",
        "formal_file_path = os.path.join(base_path, 'train', 'formal')\n",
        "informal_file_path = os.path.join(base_path, 'train', 'informal')\n",
        "\n",
        "test_formal_file_path = os.path.join(base_path, 'test', 'formal')\n",
        "test_informal_file_path = os.path.join(base_path, 'test', 'informal')\n",
        "\n",
        "# Load the sentences\n",
        "formal_sentences = load_sentences(formal_file_path)\n",
        "informal_sentences = load_sentences(informal_file_path)\n",
        "\n",
        "test_formal_sentences = load_sentences(test_formal_file_path)\n",
        "test_informal_sentences = load_sentences(test_informal_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMoSESc2PLuL",
        "outputId": "c9a13458-cbf7-49c1-9c85-08bf0ca4f8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 2 Informal Sentences: ['the movie The In-Laws not exactly a holiday movie but funny and good!', 'that page did not give me viroses(i think)']\n",
            "First 2 Formal Sentences: [\"The In-Laws movie isn't a holiday movie, but it's okay.\", \"I don't think that page gave me viruses.\"]\n",
            "First 2 Test Informal Sentences: ['Is Any Baby Really A Freak.', 'aspen colorado has he best music festivals, you sit all over the moutians its  on and just hang out']\n",
            "First 2 Test Formal Sentences: ['I like Rhythm and Blue music.', \"There's nothing he needs to change.\"]\n",
            "Number of Formal Sentences: 52595\n",
            "Number of Informal Sentences: 52595\n",
            "Number of Test Formal Sentences: 1082\n",
            "Number of Test Informal Sentences: 1416\n"
          ]
        }
      ],
      "source": [
        "# Check the first 2 loaded sentences\n",
        "print(\"First 2 Informal Sentences:\", informal_sentences[:2])\n",
        "print(\"First 2 Formal Sentences:\", formal_sentences[:2])\n",
        "\n",
        "print(\"First 2 Test Informal Sentences:\", test_informal_sentences[:2])\n",
        "print(\"First 2 Test Formal Sentences:\", test_formal_sentences[:2])\n",
        "\n",
        "# Count the number of sentences\n",
        "num_formal_sentences = len(formal_sentences)\n",
        "num_informal_sentences = len(informal_sentences)\n",
        "\n",
        "print(\"Number of Formal Sentences:\", num_formal_sentences)\n",
        "print(\"Number of Informal Sentences:\", num_informal_sentences)\n",
        "\n",
        "print(\"Number of Test Formal Sentences:\", len(test_formal_sentences))\n",
        "print(\"Number of Test Informal Sentences:\", len(test_informal_sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTpu8y_wRMIa"
      },
      "source": [
        "## 2. Preprocessing Data\n",
        "\n",
        "We will use **Character-based preprocessing.** This method involves converting all text to a uniform case, tokenizing at the character level, and padding sequences to a fixed length.\n",
        "\n",
        "It has higher accuracy in the paper (https://arxiv.org/pdf/2204.08975.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYCEN6iQRV56",
        "outputId": "e840ac14-188b-49f6-cec6-d1fa778c5057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded Sequences:\n",
            " [[ 3  9  2 ...  0  0  0]\n",
            " [ 6  1 12 ...  0  0  0]]\n",
            "Labels: [1, 1]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Combine the datasets\n",
        "all_sentences = formal_sentences + informal_sentences\n",
        "\n",
        "test_all_sentences = test_formal_sentences + test_informal_sentences\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(all_sentences)\n",
        "\n",
        "tokenizer.fit_on_texts(test_all_sentences)\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(all_sentences)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_all_sentences)\n",
        "\n",
        "# Padding sequences\n",
        "max_length = max([len(seq) for seq in sequences])  # Or you can define a max length\n",
        "X_padded = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "test_X_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Prepare labels\n",
        "y = [1] * len(formal_sentences) + [0] * len(informal_sentences)  # 1 for formal, 0 for informal\n",
        "test_y = [1] * len(test_formal_sentences) + [0] * len(test_informal_sentences)  # 1 for formal, 0 for informal\n",
        "\n",
        "# Print the first 2 padded sequences and labels\n",
        "\n",
        "print(\"Padded Sequences:\\n\", X_padded[:2])  # Show first two padded sequences\n",
        "print(\"Labels:\", y[:2])  # Show first two labels\n",
        "\n",
        "# Model Input\n",
        "X = X_padded\n",
        "test_X = test_X_padded\n",
        "\n",
        "# Model Output\n",
        "y = y\n",
        "test_y = test_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aQOMXfMSISb"
      },
      "source": [
        "## 3. Train our Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJbjvW9TSM4W"
      },
      "source": [
        "### 3.1 BiLSTM Model - Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWzuaniOSCV5",
        "outputId": "95eafce1-4a90-4007-bb13-dc38adb00242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> (105190, 3999)\n",
            "<class 'numpy.ndarray'> (105190,)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3999, 50)          6350      \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 100)               40400     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46851 (183.01 KB)\n",
            "Trainable params: 46851 (183.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "1315/1315 [==============================] - 291s 219ms/step - loss: 0.4967 - accuracy: 0.7613 - val_loss: 0.6095 - val_accuracy: 0.6948\n",
            "Epoch 2/3\n",
            "1315/1315 [==============================] - 285s 217ms/step - loss: 0.4129 - accuracy: 0.8208 - val_loss: 0.6347 - val_accuracy: 0.6562\n",
            "Epoch 3/3\n",
            "1315/1315 [==============================] - 284s 216ms/step - loss: 0.3949 - accuracy: 0.8270 - val_loss: 0.5149 - val_accuracy: 0.7172\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c21f9747670>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_padded is already defined as shown in previous steps\n",
        "# Convert X_padded and y to NumPy arrays if they aren't already\n",
        "X = np.array(X_padded)\n",
        "y = np.array(y)\n",
        "\n",
        "# Verify that X and y are now NumPy arrays\n",
        "print(type(X), X.shape)\n",
        "print(type(y), y.shape)\n",
        "\n",
        "\n",
        "# Define the BiLSTM model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=max_length),\n",
        "    Bidirectional(LSTM(units=50)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=3, batch_size=64, validation_split=0.2)  # Adjust epochs, batch_size, and validation_split as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Evaluate test predictions.\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "predictions = model.predict(test_X)\n",
        "binary_predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "precision = precision_score(test_y, binary_predictions)\n",
        "recall = recall_score(test_y, binary_predictions)\n",
        "f1 = f1_score(test_y, binary_predictions)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x60SNVBvqquY",
        "outputId": "65b63cfb-eda2-4d22-9f6c-aee942908fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 7s 77ms/step\n",
            "Precision: 0.6693174287607687\n",
            "Recall: 0.933456561922366\n",
            "F1 Score: 0.7796217676572753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvQanKrhs1KN"
      },
      "source": [
        "### 3.2 DeBerta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u76CLAqVtDNO",
        "outputId": "df356939-ee91-4846-a0c5-b170817af41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import sentencepiece\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import DebertaV2Model, DebertaV2Config, DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "\n",
        "MODEL_NAME = 'microsoft/deberta-v3-base'\n",
        "model_bert = DebertaV2ForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels=2)  # Adjust num_labels accordingly\n",
        "config = DebertaV2Config.from_pretrained(MODEL_NAME)\n",
        "tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Prepare dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=64)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import Trainer, TrainingArguments\n",
        "#tokenize dataset as per DeBerta\n",
        "#split the data 80 and 20 first\n",
        "X_train, X_val, y_train, y_val = train_test_split(all_sentences, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "eval_dataset = TextDataset(X_val, y_val)\n",
        "test_dataset = TextDataset(test_all_sentences, test_y)\n",
        "#! pip install --force-reinstall accelerate transformers[torch]\n",
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "GcxWYSPTxvsO",
        "outputId": "6e41af6c-3d96-4812-cbe0-91db7a4aa943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31557' max='31557' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [31557/31557 1:45:21, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.204700</td>\n",
              "      <td>0.211942</td>\n",
              "      <td>0.933359</td>\n",
              "      <td>0.942180</td>\n",
              "      <td>0.924800</td>\n",
              "      <td>0.933409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.182100</td>\n",
              "      <td>0.250059</td>\n",
              "      <td>0.934499</td>\n",
              "      <td>0.920816</td>\n",
              "      <td>0.952188</td>\n",
              "      <td>0.936239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.143700</td>\n",
              "      <td>0.281912</td>\n",
              "      <td>0.935830</td>\n",
              "      <td>0.923245</td>\n",
              "      <td>0.952094</td>\n",
              "      <td>0.937448</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=31557, training_loss=0.1764912257747709, metrics={'train_runtime': 6322.4194, 'train_samples_per_second': 39.93, 'train_steps_per_second': 4.991, 'total_flos': 8303144478603264.0, 'train_loss': 0.1764912257747709, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#Training\n",
        "# !pip install transformers[torch]\n",
        "#!pip install accelerate -U\n",
        "#! pip install --force-reinstall accelerate transformers[torch]\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./deBerta-results',          # where to save the model\n",
        "    evaluation_strategy=\"epoch\",     # evaluate each epoch\n",
        "    save_strategy=\"epoch\",           # save model each epoch\n",
        "    learning_rate=2e-5,              # learning rate\n",
        "    per_device_train_batch_size=8,   # batch size for training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    num_train_epochs=3,              # number of epochs\n",
        "    weight_decay=0.01,               # weight decay\n",
        "    logging_dir='./logs',            # where to store logs\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model_bert,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,  # encoded and prepared training dataset\n",
        "    eval_dataset=eval_dataset,    # encoded and prepared validation dataset\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "u0sJFb2qBe_8",
        "outputId": "7d01baf9-c2d6-4c99-dda4-6c96f868777f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DebertaV2ForSequenceClassification(\n",
              "  (deberta): DebertaV2Model(\n",
              "    (embeddings): DebertaV2Embeddings(\n",
              "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaV2Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): StableDropout()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "deberta_final_model = DebertaV2ForSequenceClassification.from_pretrained('./deBerta-results/checkpoint-31557')\n",
        "test_trainer_deberta = Trainer(deberta_final_model)\n",
        "\n",
        "deberta_raw_pred, _, _ = test_trainer_deberta.predict(test_dataset)\n",
        "deberta_y_pred = np.argmax(deberta_raw_pred, axis=1)\n",
        "#tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "deberta_final_model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    'Sentence': test_all_sentences,  # Adjust field name as necessary\n",
        "    'Predicted Label': deberta_y_pred,\n",
        "    'Actual Label': test_y  # Adjust field name as necessary\n",
        "}\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "7xVGZlJTLgq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
        "print(df_shuffled.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDWYGf65MLBj",
        "outputId": "e99ebb96-6448-4bc2-ead7-842c9e8d2dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Sentence  Predicted Label  \\\n",
            "0  my favorite english song is kiss from a rose b...                0   \n",
            "1                  neither...not a big fan of either                0   \n",
            "2  I am not fond of any of them. Panget Rock Band...                1   \n",
            "3           Goo Goo Dolls and Relient K are awesome!                1   \n",
            "4              Cheesy I know...but I love this joke.                0   \n",
            "\n",
            "   Actual Label  \n",
            "0             0  \n",
            "1             0  \n",
            "2             1  \n",
            "3             0  \n",
            "4             0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0Lr0P_Dk8xN"
      },
      "source": [
        "### 3.3 Bert (un-cased)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buuFkEKq6rEh",
        "outputId": "44ca6089-af68-492e-e498-089bc9d1a722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "\n",
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "bert_uncased = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_uncased)\n",
        "bert_uncased_model = BertForSequenceClassification.from_pretrained(bert_uncased, num_labels=2)\n",
        "\n",
        "# Prepare dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=64)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import Trainer, TrainingArguments\n",
        "#tokenize dataset as per DeBerta\n",
        "#split the data 80 and 20 first\n",
        "X_train, X_val, y_train, y_val = train_test_split(all_sentences, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train)\n",
        "eval_dataset = TextDataset(X_val, y_val)\n",
        "test_dataset = TextDataset(test_all_sentences, test_y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "cZKVVVgt63Da",
        "outputId": "3e1912db-d498-4507-df27-87cefc19cb3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31557' max='31557' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [31557/31557 1:03:41, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.381800</td>\n",
              "      <td>0.355075</td>\n",
              "      <td>0.869759</td>\n",
              "      <td>0.849172</td>\n",
              "      <td>0.902400</td>\n",
              "      <td>0.874977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.314500</td>\n",
              "      <td>0.358003</td>\n",
              "      <td>0.877840</td>\n",
              "      <td>0.851716</td>\n",
              "      <td>0.917929</td>\n",
              "      <td>0.883584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.268800</td>\n",
              "      <td>0.400761</td>\n",
              "      <td>0.881738</td>\n",
              "      <td>0.873565</td>\n",
              "      <td>0.895435</td>\n",
              "      <td>0.884365</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=31557, training_loss=0.33048393975896223, metrics={'train_runtime': 3822.8639, 'train_samples_per_second': 66.038, 'train_steps_per_second': 8.255, 'total_flos': 8302995573995520.0, 'train_loss': 0.33048393975896223, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "\n",
        "#! pip install --force-reinstall accelerate transformers[torch]\n",
        "\n",
        "# Define Trainer parameters\n",
        "# Try using a different GPU or a different version of the CUDA toolkit\n",
        "#!nvidia-smi\n",
        "#!pip install torch==1.13.1+cu117\n",
        "#!pip install transformers==4.31.0\n",
        "#!pip install accelerate -U#\n",
        "\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "# Define Trainer\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./bert-uncased\",\n",
        "    evaluation_strategy=\"epoch\",     # evaluate each epoch\n",
        "    save_strategy=\"epoch\",           # save model each epoch\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "trainer_bert_uncased = Trainer(\n",
        "    model=bert_uncased_model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")\n",
        "\n",
        "# Train pre-trained model\n",
        "trainer_bert_uncased.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"./bert-uncased/checkpoint-31557\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
        "\n",
        "raw_pred, _, _ = trainer_bert_uncased.predict(test_dataset)\n",
        "y_pred = np.argmax(raw_pred, axis=1)\n",
        "print(y_pred)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8T8IM98mfFGe",
        "outputId": "89e2e934-9329-49c4-83dd-063724e4b16a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Sentence': test_all_sentences,  # Adjust field name as necessary\n",
        "    'Predicted Label': y_pred,\n",
        "    'Actual Label': test_y  # Adjust field name as necessary\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
        "print(df_shuffled.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOPdyrvZfSGu",
        "outputId": "b60ed5fb-ea70-43d7-e3d3-c9b557fb8600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Sentence  Predicted Label  \\\n",
            "0  My little brother would ask a question like that.                1   \n",
            "1  he fired his sister because HE cant keep his m...                0   \n",
            "2          Note: i am not looking for aladdin movie.                1   \n",
            "3  Especially in regard to the chicken's pursuit ...                1   \n",
            "4  If it is an old car then you should roll the w...                1   \n",
            "\n",
            "   Actual Label  \n",
            "0             1  \n",
            "1             0  \n",
            "2             0  \n",
            "3             1  \n",
            "4             1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJeWYPMbeNu8"
      },
      "source": [
        "### 3.3 Simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoojmqO5ax5h"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(all_sentences)\n",
        "\n",
        "# Build model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 256\n",
        "\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
        "cnn_model.add(Conv1D(64, 3, activation='relu'))\n",
        "cnn_model.add(GlobalMaxPooling1D())\n",
        "cnn_model.add(Dense(32, activation='relu'))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "cnn_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "cnn_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[\"accuracy\", Precision(), Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdOtD5bOeEAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02723864-e6bb-40a7-e12e-73c47e862c6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "5260/5260 [==============================] - 82s 15ms/step - loss: 0.4245 - accuracy: 0.8165 - precision: 0.8124 - recall: 0.9184 - val_loss: 0.4255 - val_accuracy: 0.7476 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/3\n",
            "5260/5260 [==============================] - 76s 14ms/step - loss: 0.3790 - accuracy: 0.8371 - precision: 0.8348 - recall: 0.9218 - val_loss: 0.4811 - val_accuracy: 0.7408 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/3\n",
            "5260/5260 [==============================] - 77s 15ms/step - loss: 0.3648 - accuracy: 0.8427 - precision: 0.8411 - recall: 0.9225 - val_loss: 0.6029 - val_accuracy: 0.7200 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c21f8e61840>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "\n",
        "# Train model\n",
        "X = np.array(X_padded)\n",
        "y = np.array(y)\n",
        "cnn_model.fit(X, y, batch_size=16, epochs=3, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "predictions = cnn_model.predict(test_X)\n",
        "binary_predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "precision = precision_score(test_y, binary_predictions)\n",
        "recall = recall_score(test_y, binary_predictions)\n",
        "f1 = f1_score(test_y, binary_predictions)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjMNvH81hnLM",
        "outputId": "ec772c3a-0e49-44e3-d18d-d70c01aa9d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 8ms/step\n",
            "Precision: 0.6909090909090909\n",
            "Recall: 0.9482439926062847\n",
            "F1 Score: 0.7993767043241138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cnn_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su3YHX8yhofJ",
        "outputId": "1cc8ef55-5d1e-4f89-e1c4-60457c79826e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 3999, 256)         32512     \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 3997, 64)          49216     \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 64)                0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 83841 (327.50 KB)\n",
            "Trainable params: 83841 (327.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formality Score Calculations"
      ],
      "metadata": {
        "id": "QiHHDDzmh1uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Using the currently trained Bert Model, we can use it to predict formality score\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v2-xlarge\")\n",
        "model = DebertaV2ForSequenceClassification.from_pretrained('./deBerta-results/checkpoint-31557')\n",
        "test_trainer = Trainer(model)\n",
        "\n",
        "raw_pred, _, _ = test_trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(raw_pred, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "UczJGSwxh5Iy",
        "outputId": "e953be01-3754-4e52-d729-af348b26a6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_50_sentences = df_shuffled[\"Sentence\"].tolist()[:50]\n",
        "test_50_labels = df_shuffled[\"Actual Label\"].tolist()[:50]\n",
        "test_y_pred = df_shuffled[\"Predicted Label\"].tolist()[:50]"
      ],
      "metadata": {
        "id": "_a_IFsgilzvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-l8ivMGmIWx",
        "outputId": "bba04fd0-3a80-490b-e03a-a912731d8514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DebertaV2ForSequenceClassification(\n",
              "  (deberta): DebertaV2Model(\n",
              "    (embeddings): DebertaV2Embeddings(\n",
              "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaV2Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): StableDropout()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
        "inputs = tokenizer(test_50_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "y_pred = y_pred[:50]\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "    formality_scores = probabilities[:, 1].tolist()  # List of formality scores for each sentence\n"
      ],
      "metadata": {
        "id": "ZabC8cXxmQ4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294b286f-01e3-4db5-afeb-3f85c0875f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text, score, pred, model_prediction in zip(test_50_sentences, formality_scores, test_50_labels, test_y_pred):\n",
        "    print(f\"Text: {text}\\nFormality Score: {score:.4f}\\nOriginal Prediction: {pred}\\nModel Prediction: {model_prediction}\\n\")\n",
        "\n",
        "#1 for formal, 0 is informal --> the closer the score is to 0, the more informal it is, otherwise the closer it is to 1, then that is how formal it is.ok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItD0ciK2mqX-",
        "outputId": "1c3dc5cb-abe7-44e2-96d9-47676c328e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: My little brother would ask a question like that.\n",
            "Formality Score: 0.9905\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: he fired his sister because HE cant keep his mouth shut!\n",
            "Formality Score: 0.0002\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: Note: i am not looking for aladdin movie.\n",
            "Formality Score: 0.0009\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Especially in regard to the chicken's pursuit of the man during the conclusion!\n",
            "Formality Score: 0.9999\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: If it is an old car then you should roll the window down; otherwise, unlock the door.\n",
            "Formality Score: 1.0000\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: it might be an interesting show, but never got into it at all.\n",
            "Formality Score: 0.0008\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: I do not know who originally sang the song, Cry Me A River.\n",
            "Formality Score: 1.0000\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Where in the world do you come up with these questions????\n",
            "Formality Score: 0.0010\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: James, they are both terrible. Rap music is gay.\n",
            "Formality Score: 1.0000\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: However, all three can be considered part of one larger film.\n",
            "Formality Score: 1.0000\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: james both of them suck, rap is gay\n",
            "Formality Score: 0.0002\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: its keeping me up at nite, i have to know what it is\n",
            "Formality Score: 0.0002\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: I would prefer to have a thuggish 'bad boy' who also has a gentleman side.\n",
            "Formality Score: 0.9999\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Could you please repeat your question?\n",
            "Formality Score: 1.0000\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Do you know good places to become a movie starin New england?\n",
            "Formality Score: 0.0051\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: yea i feel i am an attractive person.\n",
            "Formality Score: 0.0003\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: searching the web or looking for bugs!\n",
            "Formality Score: 0.0004\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: Men would do this while others would not.\n",
            "Formality Score: 0.9992\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: I'd take magic over glow anyday!\n",
            "Formality Score: 0.0221\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: Your mom put on her job application under education, hooked on phonics.\n",
            "Formality Score: 0.9999\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: zero--- but free airfare,hotel,and meal/daytime expenses paid\n",
            "Formality Score: 0.0003\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: I also though Naomi Watts dress was really odd and looked a little too big for her also.\n",
            "Formality Score: 0.9913\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: I continue to watch the show's reruns.\n",
            "Formality Score: 1.0000\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: You are going to St. Ives.\n",
            "Formality Score: 1.0000\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: I do not like RBD either; They are older men and housewives dressing as high school students.\n",
            "Formality Score: 0.9999\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: I do not hate him but he makes me feel unpleasant.\n",
            "Formality Score: 1.0000\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: The word you are looking for is.............  strengths\n",
            "Formality Score: 0.0038\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: I would also like to spank his cute little bottom to ~ hes TOOOO cute!\n",
            "Formality Score: 0.0003\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: He assumes that people need good comedy.\n",
            "Formality Score: 1.0000\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: Secondly, I would pick 'Yellow Card', 'Simple Plan', and then 'Bowling for Soup', and 'Red Hot Chili Peppers'.\n",
            "Formality Score: 0.9996\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: ive never heard of it sorry!\n",
            "Formality Score: 0.0002\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: the brick won't follow you around after you lay it.\n",
            "Formality Score: 0.0132\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: I don't think she ever had it to begin with :).\n",
            "Formality Score: 0.0005\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: If you have to ask though, the answer is no!\n",
            "Formality Score: 0.0439\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: hard to say but i'm thinking either kevin, bucky or melissa (just because she messed up the lyrics)\n",
            "Formality Score: 0.0001\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: noo he siad that he liked her thats is what he rumor wass\n",
            "Formality Score: 0.0002\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: And sure enough he did just what he said.\n",
            "Formality Score: 0.0146\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: They do not rap about intelligent items.\n",
            "Formality Score: 1.0000\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: They are the best metal band.\n",
            "Formality Score: 1.0000\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: try purevolume.com... there are free mp3 downloads there\n",
            "Formality Score: 0.0002\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: Please don't ask me to list all of them.\n",
            "Formality Score: 0.9999\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: That is attractive, though I love Tinkerbell.\n",
            "Formality Score: 1.0000\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: different from what I've seen though\n",
            "Formality Score: 0.0003\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: (My girlfriend tried this on me last year.\n",
            "Formality Score: 0.0357\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: Cheesy I know...but I love this joke.\n",
            "Formality Score: 0.0018\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: i dont know abot the videos but you can download songs at itunes.com or limeware.com!!!!!!!!!!!!\n",
            "Formality Score: 0.0001\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: and the blonde on the highway says,  it's blondes like you that make blondes like me  look so stupid.\n",
            "Formality Score: 0.0003\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n",
            "Text: I know for sure it will be Kellie, Katherine, chris, and Ace.\n",
            "Formality Score: 0.9999\n",
            "Original Prediction: 1\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: MAYA'S HUSBAND- DARNELL, BECAUSE HE IS SO CUTE.\n",
            "Formality Score: 0.0015\n",
            "Original Prediction: 0\n",
            "Model Prediction: 1\n",
            "\n",
            "Text: now think about how many people he is hurting by keeping all his money for himself\n",
            "Formality Score: 0.0018\n",
            "Original Prediction: 0\n",
            "Model Prediction: 0\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}